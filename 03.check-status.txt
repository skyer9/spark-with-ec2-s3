
Flintrock 상태 확인하기



생성한 스파크 클러스터에 접속해서 상태를 확인한다.

1. 스파크 클러스터를 생성한다.

   $ flintrock launch spark
   Launching 2 instances...
   [13.125.251.50] SSH online.
   [13.209.21.240] SSH online.
   [13.209.21.240] Configuring ephemeral storage...
   [13.125.251.50] Configuring ephemeral storage...
   [13.125.251.50] Installing Java 1.8...
   [13.209.21.240] Installing Java 1.8...
   [13.125.251.50] Installing HDFS...
   [13.209.21.240] Installing HDFS...
   [13.125.251.50] Installing Spark...
   [13.209.21.240] Installing Spark...
   [172.31.17.187] Configuring HDFS master...
   [172.31.17.187] Configuring Spark master...
   HDFS online.
   Spark online.
   launch finished in 0:01:44.
   Cluster master: ec2-13-209-21-240.ap-northeast-2.compute.amazonaws.com
   Login with: flintrock login spark

   스파크 클러스터와 하둡 클러스터가 실행된 것을 확인할 수 있다.

2. 스파크 클러스터 작동상태를 확인한다.

   AWS 콘솔에서 마스터노드에 등록된 보안그룹 중 flintrock 으로 등록된 것에,
   브라우저를 실행할 아이피(ex PC 아이피) 에 대해 8080-8081 포트를 열도록 등록해준다.
   브라우저로 아래 주소를 열어서 클러스터 상태를 확인할 수 있다.

   http://<마스터 노드 퍼블릭 아이피>:8080/

3. 마스터노드의 내부 아이피를 등록한다.

   스파크 클러스터를 삭제 후 재생성하게 되면 내부 아이피가 변경된다.
   이를 대비해 내부 아이피를 hosts 파일에 등록해 두면 편하다.

   $ sudo vi /etc/hosts
   ......
   <마스터노드의 내부 아이피>   sparki
   ......

4. 로컬서버에서 스파크 클러스터를 실행한다.

   로컬서버에서 아래 명령을 실행한다.

   $ vi test.py
   ----------------------------------------------------------------------------
   from pyspark import SparkConf, SparkContext
   conf = SparkConf()
   conf.setMaster('spark://sparki:7077')
   conf.setAppName("simpleApp")
   sc = SparkContext(conf = conf)
   sc.stop()
   ----------------------------------------------------------------------------

   $ spark-submit test.py

5. 노트북에서 클러스터를 호출한다.

   노트북이 실행중이 아니면 아래 명령으로 노트북을 실행한다.

   $ nohup jupyter notebook &
   $ cat nohup.out

   노트북에 아래 코드를 입력해 실행할 수 있다.

   ----------------------------------------------------------------------------
   from pyspark import SparkConf, SparkContext
   conf = SparkConf()
   conf.setMaster('spark://sparki:7077')
   conf.setAppName("simpleApp")
   sc = SparkContext(conf = conf)
   sc.stop()
   ----------------------------------------------------------------------------

6. 스파크 클러스터를 종료 및 삭제한다.

   $ flintrock destroy spark

7. 기타 아래 명령을 이용할 수 있다.

   $ flintrock stop test-cluster
   $ flintrock start test-cluster

   $ flintrock describe test-cluster
   $ flintrock add-slaves test-cluster --num-slaves 2
   $ flintrock remove-slaves test-cluster --num-slaves 1
   $ flintrock run-command test-cluster 'sudo yum install -y package'

   $ flintrock copy-file test-cluster /local/path /remote/path
