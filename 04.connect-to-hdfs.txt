
Spark 클러스터에서 HDFS 접근하기



생성한 스파크 클러스터에서 하둡 파일시스템에 접속하는 것을 확인한다.

1. 스파크 클러스터를 생성한다.

   $ flintrock launch spark

   스파크 클러스터 전체에 python 3.x 를 설치한다.

   $ flintrock run-command spark 'sudo yum -y install python36'

   스파크 클러스터 마스터에 로그인한다.

   $ flintrock login spark

2. HDFS 에 파일을 복사해 넣는다.

   <SparkMaster> $ hadoop fs -copyFromLocal /home/ec2-user/hadoop/logs/*.out /
   <SparkMaster> $ hdfs dfs -ls /
   <SparkMaster> $ hdfs dfsadmin -report

3. pyspark 를 설치한다.

   pip3 를 설치한다.

   <SparkMaster> $ sudo yum -y install python36-setuptools
   <SparkMaster> $ sudo easy_install-3.6 pip

   pyspark 를 설치한다.

   <SparkMaster> $ sudo pip-3.6 install pyspark

   $ vi ~/.bashrc
   ......
   export PYSPARK_PYTHON=/usr/bin/python3
   export PYSPARK_DRIVER_PYTHON=ipython3
   export PYSPARK_DRIVER_PYTHON_OPTS="notebook"
   ......
   $ source ~/.bashrc

4. HDFS 시스템에 접근하여 파일을 읽어온다.

   <SparkMaster> $ vi test.py
   ----------------------------------------------------------------------------
   from pyspark import SparkConf, SparkContext
   conf = SparkConf()
   conf.setMaster('spark://<마스터노드 내부 아이피>:7077')
   conf.setAppName("simpleApp")
   sc = SparkContext(conf = conf)
   df = sc.textFile("hdfs:///*.out")
   print('\n\n------------------------------------------------\n\n')
   print(df.take(10))
   print('\n\n------------------------------------------------\n\n')
   sc.stop()
   ----------------------------------------------------------------------------

   <SparkMaster> $ spark-submit test.py

5. 스파크 클러스터를 종료 및 삭제한다.

   <SparkMaster> $ exit
   $ flintrock destroy spark

6. 주의사항

   코드 실행은 스파크 마스터 노드에서 해야 한다.
   원격에서 코드를 실행하게 되면, 스파크 마스터가 직접 HDFS 에 접속해 데이타를 가져오는 방식이 아니라,
   데이타가 HDFS => 원격 => 스파크 마스터노드로 이동하기 때문에 네트워크 부하가 발생하기 때문에,
   스파크 마스터에서 코드를 실행해야 한다.
